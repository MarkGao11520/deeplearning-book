
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>4.2.5 Inception-mobile_net实战 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../4.3 卷积神经网络调参/readme.html" />
    
    
    <link rel="prev" href="4.2.4  VGG-ResNet实战.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../../">
            
                <a href="../../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../../1.神经网络入门/readme.html">
            
                <a href="../../1.神经网络入门/readme.html">
            
                    
                    1.神经网络入门
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../../1.神经网络入门/1.1 神经元-逻辑斯底回归模型.html">
            
                <a href="../../1.神经网络入门/1.1 神经元-逻辑斯底回归模型.html">
            
                    
                    1.1 神经元-逻辑斯蒂回归模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../../1.神经网络入门/1.2 神经元多输出.html">
            
                <a href="../../1.神经网络入门/1.2 神经元多输出.html">
            
                    
                    1.2 神经元多输出
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="../../1.神经网络入门/1.3 梯度下降.html">
            
                <a href="../../1.神经网络入门/1.3 梯度下降.html">
            
                    
                    1.3 梯度下降与Transorflow基础
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="../../1.神经网络入门/1.4 数据处理与模型图构建.html">
            
                <a href="../../1.神经网络入门/1.4 数据处理与模型图构建.html">
            
                    
                    1.4 数据处理与模型图构建
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="../../1.神经网络入门/1.5 神经元实现.html">
            
                <a href="../../1.神经网络入门/1.5 神经元实现.html">
            
                    
                    1.5 神经元实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="../../1.神经网络入门/1.6 神经网络实现.html">
            
                <a href="../../1.神经网络入门/1.6 神经网络实现.html">
            
                    
                    1.6 神经网络实现
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../../2.前置神经网络/readme.html">
            
                <a href="../../2.前置神经网络/readme.html">
            
                    
                    2.前馈神经网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../../2.前置神经网络/2.1 网络结构.html">
            
                <a href="../../2.前置神经网络/2.1 网络结构.html">
            
                    
                    2.1 网络结构
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../../2.前置神经网络/2.2 网络结构_代码部分.html">
            
                <a href="../../2.前置神经网络/2.2 网络结构_代码部分.html">
            
                    
                    2.2 网络结构_代码部分
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../../2.前置神经网络/2.3 梯度下降法.html">
            
                <a href="../../2.前置神经网络/2.3 梯度下降法.html">
            
                    
                    2.3 梯度下降法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../../2.前置神经网络/2.4 神经网络的训练.html">
            
                <a href="../../2.前置神经网络/2.4 神经网络的训练.html">
            
                    
                    2.4 神经网络的训练
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../../2.前置神经网络/2.5 随机梯度下降法.html">
            
                <a href="../../2.前置神经网络/2.5 随机梯度下降法.html">
            
                    
                    2.5 随机梯度下降法
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../../3.提高神经网络学习效率/readme.html">
            
                <a href="../../3.提高神经网络学习效率/readme.html">
            
                    
                    3.提高神经网络学习效率
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../readme.html">
            
                <a href="../readme.html">
            
                    
                    4.卷积神经网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../4.1 卷积神经网络入门/readme.html">
            
                <a href="../4.1 卷积神经网络入门/readme.html">
            
                    
                    4.1 卷积神经网络入门
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1.1" data-path="../4.1 卷积神经网络入门/4.1.1 神经网络进阶.html">
            
                <a href="../4.1 卷积神经网络入门/4.1.1 神经网络进阶.html">
            
                    
                    4.1.1 神经网络进阶
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.2" data-path="../4.1 卷积神经网络入门/4.1.2 卷积神经网络.html">
            
                <a href="../4.1 卷积神经网络入门/4.1.2 卷积神经网络.html">
            
                    
                    4.1.2 卷积神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.3" data-path="../4.1 卷积神经网络入门/4.1.3 卷积神经网络实战.html">
            
                <a href="../4.1 卷积神经网络入门/4.1.3 卷积神经网络实战.html">
            
                    
                    4.1.3 卷积神经网络实战
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="readme.html">
            
                <a href="readme.html">
            
                    
                    4.2 卷积神经网络进阶
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.2.1" data-path="4.2.1 卷积神经网络进阶alexnet.html">
            
                <a href="4.2.1 卷积神经网络进阶alexnet.html">
            
                    
                    4.2.1 卷积神经网络进阶(alexnet)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.2" data-path="4.2.2 卷积神经网络进阶Vggnet-Resnet.html">
            
                <a href="4.2.2 卷积神经网络进阶Vggnet-Resnet.html">
            
                    
                    4.2.2 卷积神经网络进阶(Vggnet-Resnet)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.3" data-path="4.2.3 卷积神经网络进阶inception-mobile-net.html">
            
                <a href="4.2.3 卷积神经网络进阶inception-mobile-net.html">
            
                    
                    4.2.3 卷积神经网络进阶(inception-mobile-net)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.4" data-path="4.2.4  VGG-ResNet实战.html">
            
                <a href="4.2.4  VGG-ResNet实战.html">
            
                    
                    4.2.4  VGG-ResNet实战
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.5.2.5" data-path="4.2.5 Inception-mobile_net实战.html">
            
                <a href="4.2.5 Inception-mobile_net实战.html">
            
                    
                    4.2.5 Inception-mobile_net实战
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="../4.3 卷积神经网络调参/readme.html">
            
                <a href="../4.3 卷积神经网络调参/readme.html">
            
                    
                    4.3 卷积神经网络调参
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.4" data-path="../4.4 图像风格转换/readme.html">
            
                <a href="../4.4 图像风格转换/readme.html">
            
                    
                    4.4 图像风格转换
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../../5.循环神经网络/readme.html">
            
                <a href="../../5.循环神经网络/readme.html">
            
                    
                    5.循环神经网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../../5.循环神经网络/5.1 循环神经网络入门到进阶/readme.html">
            
                <a href="../../5.循环神经网络/5.1 循环神经网络入门到进阶/readme.html">
            
                    
                    5.1 循环神经网络入门到进阶
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="../../5.循环神经网络/5.2 图像生成文本/readme.html">
            
                <a href="../../5.循环神经网络/5.2 图像生成文本/readme.html">
            
                    
                    5.2 图像生成文本
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../../6.对抗神经网络/readme.html">
            
                <a href="../../6.对抗神经网络/readme.html">
            
                    
                    6.对抗神经网络
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../.." >4.2.5 Inception-mobile_net实战</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="425-inception-mobilenet&#x5B9E;&#x6218;">4.2.5 Inception-mobile_net&#x5B9E;&#x6218;</h1>
<ul>
<li><h3 id="inception-net">Inception-Net</h3>
<p>Inception Net&#x7684;&#x601D;&#x60F3;&#x662F;&#x5206;&#x7EC4;&#x5377;&#x79EF;&#xFF0C;&#x4E0A;&#x4E00;&#x5C42;&#x5206;&#x6210;&#x51E0;&#x7EC4;&#x5377;&#x79EF;&#xFF0C;&#x5377;&#x79EF;&#x5B8C;&#x6210;&#x4E4B;&#x540E;&#x5728;&#x628A;&#x5206;&#x7EC4;&#x7684;&#x7ED3;&#x679C;&#x62FC;&#x63A5;&#x8D77;&#x6765;</p>
<p>&#x53EF;&#x4EE5;&#x8FDB;&#x884C;&#x6269;&#x5C55;&#xFF0C;&#x6BCF;&#x4E2A;&#x7EC4;&#x6709;&#x5F88;&#x591A;&#x5C42;&#xFF0C;&#x8FD9;&#x91CC;&#x53EA;&#x5B9E;&#x73B0;&#x57FA;&#x672C;&#x7684;&#x5206;&#x7EC4;&#x5377;&#x79EF;</p>
<p>```python</p>
<h1 id="&#x5B9A;&#x4E49;-inception-net&#x7684;&#x5206;&#x7EC4;&#x7ED3;&#x6784;">&#x5B9A;&#x4E49; Inception-Net&#x7684;&#x5206;&#x7EC4;&#x7ED3;&#x6784;</h1>
<p>def inception_block(x,</p>
<pre><code>              output_channel_for_each_path,
              name):
&quot;&quot;&quot;inception block implementation&quot;&quot;&quot;
&quot;&quot;&quot;
Args:
- x: &#x8F93;&#x5165;&#x6570;&#x636E;
- output_channel_for_each_path: &#x6BCF;&#x7EC4;&#x7684;&#x8F93;&#x51FA;&#x901A;&#x9053;&#x6570;&#x76EE; eg: [10,20,30]
- name: &#x6BCF;&#x7EC4;&#x7684;&#x5377;&#x79EF;&#x547D;&#x540D;
&quot;&quot;&quot;
# variable_scope &#x5728;&#x8FD9;&#x4E2A;scope&#x4E0B;&#x547D;&#x540D;&#x4E0D;&#x4F1A;&#x6709;&#x51B2;&#x7A81; conv1 = &apos;conv1&apos; =&gt; scope_name/conv1
with tf.variable_scope(name):
    conv1_1 = tf.layers.conv2d(x,
                               output_channel_for_each_path[0],
                               (1, 1),
                               strides = (1,1),
                               padding = &apos;same&apos;,
                               activation = tf.nn.relu,
                               name = &apos;conv1_1&apos;)

    conv3_3 = tf.layers.conv2d(x,
                               output_channel_for_each_path[1],
                               (3, 3),
                               strides = (1,1),
                               padding = &apos;same&apos;,
                               activation = tf.nn.relu,
                               name = &apos;conv3_3&apos;)
    conv5_5 = tf.layers.conv2d(x,
                               output_channel_for_each_path[0],
                               (5, 5),
                               strides = (1,1),
                               padding = &apos;same&apos;,
                               activation = tf.nn.relu,
                               name = &apos;conv5_5&apos;)
    max_pooling = tf.layers.max_pooling2d(x,
                                        (2,2),
                                        (2,2),
                                        name = &apos;max_pooling&apos;)

    # max_pooling &#x4F1A;&#x4F7F;&#x5F97;&#x56FE;&#x50CF;&#x53D8;&#x5C0F;&#xFF0C;&#x6240;&#x4EE5;&#x9700;&#x8981;padding
    max_pooling_shape = max_pooling.get_shape().as_list()[1:]
    input_shape = x.get_shape().as_list()[1:]
    width_padding = (input_shape[0] - max_pooling_shape[0]) // 2
    height_padding = (input_shape[1] - max_pooling_shape[1]) // 2
    padded_pooling = tf.pad(max_pooling,
                            [[0,0],
                             [width_padding,width_padding],
                             [height_padding,height_padding],
                             [0,0]])

    # &#x5728;&#x7B2C;&#x56DB;&#x4E2A;&#x7EF4;&#x5EA6;&#xFF08;&#x901A;&#x9053;&#x6570;&#xFF09;&#x4E0A;&#x505A;&#x62FC;&#x63A5;
    concat_layer = tf.concat(
        [conv1_1, conv3_3, conv5_5, padded_pooling],
        axis = 3)
    return concat_layer
</code></pre><p>x = tf.placeholder(tf.float32, [None, 3072])
y = tf.placeholder(tf.int64, [None])</p>
<h1 id="&#x5C06;&#x5411;&#x91CF;&#x53D8;&#x6210;&#x5177;&#x6709;&#x4E09;&#x901A;&#x9053;&#x7684;&#x56FE;&#x7247;&#x7684;&#x683C;&#x5F0F;">&#x5C06;&#x5411;&#x91CF;&#x53D8;&#x6210;&#x5177;&#x6709;&#x4E09;&#x901A;&#x9053;&#x7684;&#x56FE;&#x7247;&#x7684;&#x683C;&#x5F0F;</h1>
<p>x_image = tf.reshape(x, [-1,3,32,32])</p>
<h1 id="3232">32*32</h1>
<p>x_image = tf.transpose(x_image, perm = [0, 2, 3, 1])</p>
<h1 id="&#x5148;&#x7ECF;&#x8FC7;&#x4E00;&#x4E2A;&#x666E;&#x901A;&#x7684;&#x5377;&#x79EF;&#x5C42;&#x548C;&#x6C60;&#x5316;&#x5C42;">&#x5148;&#x7ECF;&#x8FC7;&#x4E00;&#x4E2A;&#x666E;&#x901A;&#x7684;&#x5377;&#x79EF;&#x5C42;&#x548C;&#x6C60;&#x5316;&#x5C42;</h1>
<h1 id="conv1&#xFF1A;&#x795E;&#x7ECF;&#x5143;&#x56FE;feature-map&#x8F93;&#x51FA;&#x56FE;&#x50CF;">conv1&#xFF1A;&#x795E;&#x7ECF;&#x5143;&#x56FE;,feature map,&#x8F93;&#x51FA;&#x56FE;&#x50CF;</h1>
<p>conv1 = tf.layers.conv2d(x_image,</p>
<pre><code>                       32, # output channel number
                       (3,3), # kernal size
                       padding = &apos;same&apos;, # same &#x4EE3;&#x8868;&#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5927;&#x5C0F;&#x6CA1;&#x6709;&#x53D8;&#x5316;&#xFF0C;valid &#x4EE3;&#x8868;&#x4E0D;&#x505A;padding
                       activation = tf.nn.relu,
                       name = &apos;conv1&apos;)
</code></pre><h1 id="1616">16*16</h1>
<p>pooling1 = tf.layers.max_pooling2d(conv1,</p>
<pre><code>                               (2, 2), # kernal size
                               (2, 2), # stride
                               name = &apos;pool1&apos; # name&#x4E3A;&#x4E86;&#x7ED9;&#x8FD9;&#x4E00;&#x5C42;&#x505A;&#x4E00;&#x4E2A;&#x547D;&#x540D;&#xFF0C;&#x8FD9;&#x6837;&#x4F1A;&#x8BA9;&#x56FE;&#x6253;&#x5370;&#x51FA;&#x6765;&#x7684;&#x65F6;&#x5019;&#x4F1A;&#x662F;&#x4E00;&#x4E2A;&#x6709;&#x610F;&#x4E49;&#x7684;&#x56FE;
                              )
</code></pre><h1 id="&#x7ECF;&#x8FC7;&#x4E24;&#x4E2A;&#x4E2A;&#x5206;&#x7EC4;&#x5377;&#x79EF;">&#x7ECF;&#x8FC7;&#x4E24;&#x4E2A;&#x4E2A;&#x5206;&#x7EC4;&#x5377;&#x79EF;</h1>
<p>inception_2a = inception_block(pooling1, </p>
<pre><code>                           [16, 16, 16],
                           name = &apos;inception_2a&apos;)
</code></pre><p>inception_2b = inception_block(inception_2a, </p>
<pre><code>                           [16, 16, 16],
                           name = &apos;inception_2b&apos;)
</code></pre><h1 id="&#x63A5;&#x4E00;&#x4E2A;&#x6C60;&#x5316;">&#x63A5;&#x4E00;&#x4E2A;&#x6C60;&#x5316;</h1>
<p>pooling2 = tf.layers.max_pooling2d(inception_2b,</p>
<pre><code>                               (2, 2), 
                               (2, 2), 
                               name = &apos;pool2&apos; 
                              )
</code></pre><h1 id="&#x518D;&#x7ECF;&#x8FC7;&#x4E24;&#x4E2A;&#x5206;&#x7EC4;&#x5377;&#x79EF;&#x6838;&#x4E00;&#x4E2A;&#x6C60;&#x5316;">&#x518D;&#x7ECF;&#x8FC7;&#x4E24;&#x4E2A;&#x5206;&#x7EC4;&#x5377;&#x79EF;&#x6838;&#x4E00;&#x4E2A;&#x6C60;&#x5316;</h1>
<p>inception_3a = inception_block(pooling2, </p>
<pre><code>                           [16, 16, 16],
                           name = &apos;inception_3a&apos;)
</code></pre><p>inception_3b = inception_block(inception_3a, </p>
<pre><code>                           [16, 16, 16],
                           name = &apos;inception_3b&apos;)
</code></pre><p>pooling3 = tf.layers.max_pooling2d(inception_3b,</p>
<pre><code>                               (2, 2), 
                               (2, 2), 
                               name = &apos;pool3&apos; 
                              )
</code></pre><h1 id="none-4442-&#x5C06;&#x4E09;&#x901A;&#x9053;&#x7684;&#x56FE;&#x5F62;&#x8F6C;&#x6362;&#x6210;&#x77E9;&#x9635;">[None, 4<em>4</em>42] &#x5C06;&#x4E09;&#x901A;&#x9053;&#x7684;&#x56FE;&#x5F62;&#x8F6C;&#x6362;&#x6210;&#x77E9;&#x9635;</h1>
<p>flatten = tf.layers.flatten(pooling3)
y_ = tf.layers.dense(flatten, 10)</p>
</li>
</ul>
<h1 id="&#x4EA4;&#x53C9;&#x71B5;">&#x4EA4;&#x53C9;&#x71B5;</h1>
<p>  loss = tf.losses.sparse<em>softmax_cross_entropy(labels=y, logits=y</em>)</p>
<h1 id="y--softmax">y_-&gt; softmax</h1>
<h1 id="y---onehot">y -&gt; one_hot</h1>
<h1 id="loss--ylogy">loss = ylogy_</h1>
<h1 id="bool">bool</h1>
<p>  predict = tf.argmax(y_, 1)</p>
<h1 id="10111000">[1,0,1,1,1,0,0,0]</h1>
<p>  correct_prediction = tf.equal(predict, y)
  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))</p>
<p>  with tf.name_scope(&apos;train_op&apos;):
      train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)</p>
<pre><code>
- Mobile-Net

  Mobile Net &#x7684;&#x57FA;&#x672C;&#x7ED3;&#x6784; &#x6DF1;&#x5EA6;&#x53EF;&#x5206;&#x7C7B;&#x7684;&#x5377;&#x79EF; -&gt; BN -&gt;RELU-&gt; 1\*1 &#x7684;&#x5377;&#x79EF; -&gt; BN -&gt; RELU 

  &#x8FD9;&#x91CC;BN&#x5148;&#x4E0D;&#x52A0;&#xFF0C;&#x8FD9;&#x662F;&#x4E0B;&#x8282;&#x8BFE;&#x7684;&#x5185;&#x5BB9;

  ![image.png](https://upload-images.jianshu.io/upload_images/7220971-38181b219ed82b1b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
</code></pre><p>  def separable_conv_block(x,
                    output_channel_number,
                    name):
      &quot;&quot;&quot;separable_conv block implementation&quot;&quot;&quot;
      &quot;&quot;&quot;
      Args:</p>
<pre><code>  - x: &#x8F93;&#x5165;&#x6570;&#x636E;
  - output_channel_number: &#x7ECF;&#x8FC7;&#x6DF1;&#x5EA6;&#x53EF;&#x5206;&#x79BB;&#x5377;&#x79EF;&#x4E4B;&#x540E;&#xFF0C;&#x518D;&#x7ECF;&#x8FC7;1*1 &#x7684;&#x5377;&#x79EF;&#x751F;&#x6210;&#x7684;&#x901A;&#x9053;&#x6570;&#x76EE;
  - name: &#x6BCF;&#x7EC4;&#x7684;&#x5377;&#x79EF;&#x547D;&#x540D;
  &quot;&quot;&quot;
  # variable_scope &#x5728;&#x8FD9;&#x4E2A;scope&#x4E0B;&#x547D;&#x540D;&#x4E0D;&#x4F1A;&#x6709;&#x51B2;&#x7A81; conv1 = &apos;conv1&apos; =&gt; scope_name/conv1
  with tf.variable_scope(name):
      input_channel = x.get_shape().as_list()[-1]
      # &#x5C06;x &#x5728; &#x7B2C;&#x56DB;&#x4E2A;&#x7EF4;&#x5EA6;&#xFF08;axis+1&#xFF09; &#x4E0A; &#x62C6;&#x5206;&#x6210; input_channel &#x4EFD;
      # channel_wise_x: [channel1, channel2, ...]
      channel_wise_x = tf.split(x, input_channel, axis = 3)
      output_channels = []
      for i in range(len(channel_wise_x)):
          output_channel = tf.layers.conv2d(channel_wise_x[i],
                                            1,
                                            (3,3),
                                            strides = (1,1),
                                            padding = &apos;same&apos;,
                                            activation = tf.nn.relu,
                                            name = &apos;conv_%d&apos; % i)
          output_channels.append(output_channel)
      concat_layers = tf.concat(output_channels, axis = 3)
      conv1_1 = tf.layers.conv2d(concat_layers,
                                 output_channel_number,
                                 (1,1),
                                 strides = (1,1),
                                 padding = &apos;same&apos;,
                                 activation = tf.nn.relu,
                                 name = &apos;conv1_1&apos;)
      return conv1_1
</code></pre><p>  x = tf.placeholder(tf.float32, [None, 3072])
  y = tf.placeholder(tf.int64, [None])</p>
<h1 id="&#x5C06;&#x5411;&#x91CF;&#x53D8;&#x6210;&#x5177;&#x6709;&#x4E09;&#x901A;&#x9053;&#x7684;&#x56FE;&#x7247;&#x7684;&#x683C;&#x5F0F;">&#x5C06;&#x5411;&#x91CF;&#x53D8;&#x6210;&#x5177;&#x6709;&#x4E09;&#x901A;&#x9053;&#x7684;&#x56FE;&#x7247;&#x7684;&#x683C;&#x5F0F;</h1>
<p>  x_image = tf.reshape(x, [-1,3,32,32])</p>
<h1 id="3232">32*32</h1>
<p>  x_image = tf.transpose(x_image, perm = [0, 2, 3, 1])</p>
<h1 id="conv1&#xFF1A;&#x795E;&#x7ECF;&#x5143;&#x56FE;feature-map&#x8F93;&#x51FA;&#x56FE;&#x50CF;">conv1&#xFF1A;&#x795E;&#x7ECF;&#x5143;&#x56FE;,feature map,&#x8F93;&#x51FA;&#x56FE;&#x50CF;</h1>
<p>  conv1 = tf.layers.conv2d(x_image,
                             32, # output channel number
                             (3,3), # kernal size
                             padding = &apos;same&apos;, # same &#x4EE3;&#x8868;&#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5927;&#x5C0F;&#x6CA1;&#x6709;&#x53D8;&#x5316;&#xFF0C;valid &#x4EE3;&#x8868;&#x4E0D;&#x505A;padding
                             activation = tf.nn.relu,
                             name = &apos;conv1&apos;)</p>
<h1 id="1616">16*16</h1>
<p>  pooling1 = tf.layers.max_pooling2d(conv1,
                                     (2, 2), # kernal size
                                     (2, 2), # stride
                                     name = &apos;pool1&apos; # name&#x4E3A;&#x4E86;&#x7ED9;&#x8FD9;&#x4E00;&#x5C42;&#x505A;&#x4E00;&#x4E2A;&#x547D;&#x540D;&#xFF0C;&#x8FD9;&#x6837;&#x4F1A;&#x8BA9;&#x56FE;&#x6253;&#x5370;&#x51FA;&#x6765;&#x7684;&#x65F6;&#x5019;&#x4F1A;&#x662F;&#x4E00;&#x4E2A;&#x6709;&#x610F;&#x4E49;&#x7684;&#x56FE;
                                    )</p>
<p>  separable_2a = separable_conv_block(pooling1, 
                                      32,
                                      name = &apos;separable_2a&apos;)</p>
<p>  separable_2b = separable_conv_block(separable_2a, 
                                      32,
                                      name = &apos;separable_2b&apos;)</p>
<p>  pooling2 = tf.layers.max_pooling2d(separable_2b,
                                     (2, 2), 
                                     (2, 2), 
                                     name = &apos;pool2&apos; 
                                    )</p>
<p>  separable_3a = separable_conv_block(pooling2, 
                                      32,
                                      name = &apos;separable_3a&apos;)</p>
<p>  separable_3b = separable_conv_block(separable_3a, 
                                      32,
                                      name = &apos;separable_3b&apos;)</p>
<p>  pooling3 = tf.layers.max_pooling2d(separable_3b,
                                     (2, 2), 
                                     (2, 2), 
                                     name = &apos;pool3&apos;)</p>
<h1 id="none-4442-&#x5C06;&#x4E09;&#x901A;&#x9053;&#x7684;&#x56FE;&#x5F62;&#x8F6C;&#x6362;&#x6210;&#x77E9;&#x9635;">[None, 4<em>4</em>42] &#x5C06;&#x4E09;&#x901A;&#x9053;&#x7684;&#x56FE;&#x5F62;&#x8F6C;&#x6362;&#x6210;&#x77E9;&#x9635;</h1>
<p>  flatten = tf.layers.flatten(pooling3)
  y_ = tf.layers.dense(flatten, 10)</p>
<h1 id="&#x4EA4;&#x53C9;&#x71B5;">&#x4EA4;&#x53C9;&#x71B5;</h1>
<p>  loss = tf.losses.sparse<em>softmax_cross_entropy(labels=y, logits=y</em>)</p>
<h1 id="y--softmax">y_-&gt; softmax</h1>
<h1 id="y---onehot">y -&gt; one_hot</h1>
<h1 id="loss--ylogy">loss = ylogy_</h1>
<h1 id="bool">bool</h1>
<p>  predict = tf.argmax(y_, 1)</p>
<h1 id="10111000">[1,0,1,1,1,0,0,0]</h1>
<p>  correct_prediction = tf.equal(predict, y)
  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))</p>
<p>  with tf.name_scope(&apos;train_op&apos;):
      train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)
  ```</p>
<p>  &#x8FD9;&#x91CC;&#x7684;&#x51C6;&#x786E;&#x7387;&#x662F;10000&#x6B21;&#x767E;&#x5206;&#x4E4B;60&#xFF0C;&#x8FD9;&#x662F;&#x56E0;&#x4E3A;mobile net &#x7684; &#x53C2;&#x6570;&#x51CF;&#x5C0F;&#x548C;&#x8BA1;&#x7B97;&#x7387;&#x51CF;&#x5C0F;&#x5F71;&#x54CD;&#x4E86;&#x51C6;&#x786E;&#x7387;&#x3002;</p>
<ul>
<li>&#x8FD9;&#x91CC;&#x7684;&#x8BAD;&#x7EC3;&#x6211;&#x4EEC;&#x90FD;&#x4F7F;&#x7528;&#x7684;&#x662F;&#x4E00;&#x4E07;&#x6B21;&#x8BAD;&#x7EC3;&#xFF0C;&#x771F;&#x6B63;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x8BAD;&#x7EC3;&#x8FDC;&#x4E0D;&#x6B62;&#x4E8E;&#x6B64;&#xFF0C;&#x53EF;&#x80FD;&#x4F1A;&#x8FBE;&#x5230;100&#x4E07;&#x6B21;&#x7684;&#x89C4;&#x6A21;</li>
</ul>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="4.2.4  VGG-ResNet实战.html" class="navigation navigation-prev " aria-label="Previous page: 4.2.4  VGG-ResNet实战">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../4.3 卷积神经网络调参/readme.html" class="navigation navigation-next " aria-label="Next page: 4.3 卷积神经网络调参">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"4.2.5 Inception-mobile_net实战","level":"1.5.2.5","depth":3,"next":{"title":"4.3 卷积神经网络调参","level":"1.5.3","depth":2,"path":"4.卷积神经网络/4.3 卷积神经网络调参/readme.md","ref":"4.卷积神经网络/4.3 卷积神经网络调参/readme.md","articles":[]},"previous":{"title":"4.2.4  VGG-ResNet实战","level":"1.5.2.4","depth":3,"path":"4.卷积神经网络/4.2 卷积神经网络进阶/4.2.4  VGG-ResNet实战.md","ref":"4.卷积神经网络/4.2 卷积神经网络进阶/4.2.4  VGG-ResNet实战.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["livereload"],"pluginsConfig":{"livereload":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"4.卷积神经网络/4.2 卷积神经网络进阶/4.2.5 Inception-mobile_net实战.md","mtime":"2018-10-07T05:32:29.260Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2018-10-07T04:57:01.194Z"},"basePath":"../..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../../gitbook/gitbook.js"></script>
    <script src="../../gitbook/theme.js"></script>
    
        
        <script src="../../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

