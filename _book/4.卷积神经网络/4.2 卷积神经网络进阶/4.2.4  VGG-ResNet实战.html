
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>4.2.4  VGG-ResNet实战 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="4.2.5 Inception-mobile_net实战.html" />
    
    
    <link rel="prev" href="4.2.3 卷积神经网络进阶inception-mobile-net.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../../">
            
                <a href="../../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../../1.神经网络入门/readme.html">
            
                <a href="../../1.神经网络入门/readme.html">
            
                    
                    1.神经网络入门
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../../1.神经网络入门/1.1 神经元-逻辑斯底回归模型.html">
            
                <a href="../../1.神经网络入门/1.1 神经元-逻辑斯底回归模型.html">
            
                    
                    1.1 神经元-逻辑斯蒂回归模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../../1.神经网络入门/1.2 神经元多输出.html">
            
                <a href="../../1.神经网络入门/1.2 神经元多输出.html">
            
                    
                    1.2 神经元多输出
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="../../1.神经网络入门/1.3 梯度下降.html">
            
                <a href="../../1.神经网络入门/1.3 梯度下降.html">
            
                    
                    1.3 梯度下降与Transorflow基础
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="../../1.神经网络入门/1.4 数据处理与模型图构建.html">
            
                <a href="../../1.神经网络入门/1.4 数据处理与模型图构建.html">
            
                    
                    1.4 数据处理与模型图构建
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="../../1.神经网络入门/1.5 神经元实现.html">
            
                <a href="../../1.神经网络入门/1.5 神经元实现.html">
            
                    
                    1.5 神经元实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="../../1.神经网络入门/1.6 神经网络实现.html">
            
                <a href="../../1.神经网络入门/1.6 神经网络实现.html">
            
                    
                    1.6 神经网络实现
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../../2.前置神经网络/readme.html">
            
                <a href="../../2.前置神经网络/readme.html">
            
                    
                    2.前馈神经网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../../2.前置神经网络/2.1 网络结构.html">
            
                <a href="../../2.前置神经网络/2.1 网络结构.html">
            
                    
                    2.1 网络结构
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../../2.前置神经网络/2.2 网络结构_代码部分.html">
            
                <a href="../../2.前置神经网络/2.2 网络结构_代码部分.html">
            
                    
                    2.2 网络结构_代码部分
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../../2.前置神经网络/2.3 梯度下降法.html">
            
                <a href="../../2.前置神经网络/2.3 梯度下降法.html">
            
                    
                    2.3 梯度下降法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../../2.前置神经网络/2.4 神经网络的训练.html">
            
                <a href="../../2.前置神经网络/2.4 神经网络的训练.html">
            
                    
                    2.4 神经网络的训练
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../../2.前置神经网络/2.5 随机梯度下降法.html">
            
                <a href="../../2.前置神经网络/2.5 随机梯度下降法.html">
            
                    
                    2.5 随机梯度下降法
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../../3.提高神经网络学习效率/readme.html">
            
                <a href="../../3.提高神经网络学习效率/readme.html">
            
                    
                    3.提高神经网络学习效率
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../readme.html">
            
                <a href="../readme.html">
            
                    
                    4.卷积神经网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../4.1 卷积神经网络入门/readme.html">
            
                <a href="../4.1 卷积神经网络入门/readme.html">
            
                    
                    4.1 卷积神经网络入门
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1.1" data-path="../4.1 卷积神经网络入门/4.1.1 神经网络进阶.html">
            
                <a href="../4.1 卷积神经网络入门/4.1.1 神经网络进阶.html">
            
                    
                    4.1.1 神经网络进阶
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.2" data-path="../4.1 卷积神经网络入门/4.1.2 卷积神经网络.html">
            
                <a href="../4.1 卷积神经网络入门/4.1.2 卷积神经网络.html">
            
                    
                    4.1.2 卷积神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.3" data-path="../4.1 卷积神经网络入门/4.1.3 卷积神经网络实战.html">
            
                <a href="../4.1 卷积神经网络入门/4.1.3 卷积神经网络实战.html">
            
                    
                    4.1.3 卷积神经网络实战
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="readme.html">
            
                <a href="readme.html">
            
                    
                    4.2 卷积神经网络进阶
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.2.1" data-path="4.2.1 卷积神经网络进阶alexnet.html">
            
                <a href="4.2.1 卷积神经网络进阶alexnet.html">
            
                    
                    4.2.1 卷积神经网络进阶(alexnet)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.2" data-path="4.2.2 卷积神经网络进阶Vggnet-Resnet.html">
            
                <a href="4.2.2 卷积神经网络进阶Vggnet-Resnet.html">
            
                    
                    4.2.2 卷积神经网络进阶(Vggnet-Resnet)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.3" data-path="4.2.3 卷积神经网络进阶inception-mobile-net.html">
            
                <a href="4.2.3 卷积神经网络进阶inception-mobile-net.html">
            
                    
                    4.2.3 卷积神经网络进阶(inception-mobile-net)
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.5.2.4" data-path="4.2.4  VGG-ResNet实战.html">
            
                <a href="4.2.4  VGG-ResNet实战.html">
            
                    
                    4.2.4  VGG-ResNet实战
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.5" data-path="4.2.5 Inception-mobile_net实战.html">
            
                <a href="4.2.5 Inception-mobile_net实战.html">
            
                    
                    4.2.5 Inception-mobile_net实战
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="../4.3 卷积神经网络调参/readme.html">
            
                <a href="../4.3 卷积神经网络调参/readme.html">
            
                    
                    4.3 卷积神经网络调参
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.4" data-path="../4.4 图像风格转换/readme.html">
            
                <a href="../4.4 图像风格转换/readme.html">
            
                    
                    4.4 图像风格转换
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../../5.循环神经网络/readme.html">
            
                <a href="../../5.循环神经网络/readme.html">
            
                    
                    5.循环神经网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../../5.循环神经网络/5.1 循环神经网络入门到进阶/readme.html">
            
                <a href="../../5.循环神经网络/5.1 循环神经网络入门到进阶/readme.html">
            
                    
                    5.1 循环神经网络入门到进阶
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="../../5.循环神经网络/5.2 图像生成文本/readme.html">
            
                <a href="../../5.循环神经网络/5.2 图像生成文本/readme.html">
            
                    
                    5.2 图像生成文本
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../../6.对抗神经网络/readme.html">
            
                <a href="../../6.对抗神经网络/readme.html">
            
                    
                    6.对抗神经网络
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../.." >4.2.4  VGG-ResNet实战</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="424--vgg-resnet&#x5B9E;&#x6218;">4.2.4  VGG-ResNet&#x5B9E;&#x6218;</h1>
<ul>
<li><h3 id="vggnet&#x5B9E;&#x6218;">VGGNET&#x5B9E;&#x6218;</h3>
<p>VGGNET&#x7684;&#x601D;&#x60F3;&#x5C31;&#x662F;&#x52A0;&#x6DF1;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5C42;&#x6B21;&#xFF0C;&#x591A;&#x4F7F;&#x7528;3*3&#x7684;&#x5377;&#x79EF;&#x6838;&#x66FF;&#x6362;5*5&#x7684;</p>
<p>&#x8FD9;&#x91CC;&#x6211;&#x4EEC;&#x5C31;&#x4E0D;&#x4F7F;&#x7528;1*1&#x7684;&#x5377;&#x79EF;&#x6838;&#x4E86;</p>
<p>&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5728;&#x4E4B;&#x524D;&#x7684;&#x5377;&#x79EF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x57FA;&#x7840;&#x4E0A;&#x590D;&#x7528;&#x6570;&#x636E;&#x5904;&#x7406;&#x548C;&#x6D4B;&#x8BD5;&#x7684;&#x4EE3;&#x7801;</p>
<p>&#x53EA;&#x4FEE;&#x6539;&#x5377;&#x79EF;&#x5C42;&#x90E8;&#x5206;</p>
<pre><code class="lang-python"><span class="hljs-comment"># conv1&#xFF1A;&#x795E;&#x7ECF;&#x5143;&#x56FE;,feature map,&#x8F93;&#x51FA;&#x56FE;&#x50CF;</span>
conv1_1 = tf.layers.conv2d(x_image,
                         <span class="hljs-number">32</span>, <span class="hljs-comment"># output channel number</span>
                         (<span class="hljs-number">3</span>,<span class="hljs-number">3</span>), <span class="hljs-comment"># kernal size</span>
                         padding = <span class="hljs-string">&apos;same&apos;</span>, <span class="hljs-comment"># same &#x4EE3;&#x8868;&#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5927;&#x5C0F;&#x6CA1;&#x6709;&#x53D8;&#x5316;&#xFF0C;valid &#x4EE3;&#x8868;&#x4E0D;&#x505A;padding</span>
                         activation = tf.nn.relu,
                         name = <span class="hljs-string">&apos;conv1_1&apos;</span>
                         )
conv1_2 = tf.layers.conv2d(conv1_1,
                         <span class="hljs-number">32</span>, <span class="hljs-comment"># output channel number</span>
                         (<span class="hljs-number">3</span>,<span class="hljs-number">3</span>), <span class="hljs-comment"># kernal size</span>
                         padding = <span class="hljs-string">&apos;same&apos;</span>, <span class="hljs-comment"># same &#x4EE3;&#x8868;&#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5927;&#x5C0F;&#x6CA1;&#x6709;&#x53D8;&#x5316;&#xFF0C;valid &#x4EE3;&#x8868;&#x4E0D;&#x505A;padding</span>
                         activation = tf.nn.relu,
                         name = <span class="hljs-string">&apos;conv1_2&apos;</span>
                         )
<span class="hljs-comment"># 16*16</span>
pooling1 = tf.layers.max_pooling2d(conv1_2,
                                   (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), <span class="hljs-comment"># kernal size</span>
                                   (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), <span class="hljs-comment"># stride</span>
                                   name = <span class="hljs-string">&apos;pool1&apos;</span> <span class="hljs-comment"># name&#x4E3A;&#x4E86;&#x7ED9;&#x8FD9;&#x4E00;&#x5C42;&#x505A;&#x4E00;&#x4E2A;&#x547D;&#x540D;&#xFF0C;&#x8FD9;&#x6837;&#x4F1A;&#x8BA9;&#x56FE;&#x6253;&#x5370;&#x51FA;&#x6765;&#x7684;&#x65F6;&#x5019;&#x4F1A;&#x662F;&#x4E00;&#x4E2A;&#x6709;&#x610F;&#x4E49;&#x7684;&#x56FE;</span>
                                  )

conv2_1 = tf.layers.conv2d(pooling1,
                         <span class="hljs-number">32</span>, <span class="hljs-comment"># output channel number</span>
                         (<span class="hljs-number">3</span>,<span class="hljs-number">3</span>), <span class="hljs-comment"># kernal size</span>
                         padding = <span class="hljs-string">&apos;same&apos;</span>, <span class="hljs-comment"># same &#x4EE3;&#x8868;&#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5927;&#x5C0F;&#x6CA1;&#x6709;&#x53D8;&#x5316;&#xFF0C;valid &#x4EE3;&#x8868;&#x4E0D;&#x505A;padding</span>
                         activation = tf.nn.relu,
                         name = <span class="hljs-string">&apos;conv2_1&apos;</span>
                         )

conv2_2 = tf.layers.conv2d(conv2_1,
                         <span class="hljs-number">32</span>, <span class="hljs-comment"># output channel number</span>
                         (<span class="hljs-number">3</span>,<span class="hljs-number">3</span>), <span class="hljs-comment"># kernal size</span>
                         padding = <span class="hljs-string">&apos;same&apos;</span>, <span class="hljs-comment"># same &#x4EE3;&#x8868;&#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5927;&#x5C0F;&#x6CA1;&#x6709;&#x53D8;&#x5316;&#xFF0C;valid &#x4EE3;&#x8868;&#x4E0D;&#x505A;padding</span>
                         activation = tf.nn.relu,
                         name = <span class="hljs-string">&apos;conv2_2&apos;</span>
                         )
<span class="hljs-comment"># 8*8</span>
pooling2 = tf.layers.max_pooling2d(conv2_2,
                                   (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), <span class="hljs-comment"># kernal size</span>
                                   (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), <span class="hljs-comment"># stride</span>
                                   name = <span class="hljs-string">&apos;pool2&apos;</span> <span class="hljs-comment"># name&#x4E3A;&#x4E86;&#x7ED9;&#x8FD9;&#x4E00;&#x5C42;&#x505A;&#x4E00;&#x4E2A;&#x547D;&#x540D;&#xFF0C;&#x8FD9;&#x6837;&#x4F1A;&#x8BA9;&#x56FE;&#x6253;&#x5370;&#x51FA;&#x6765;&#x7684;&#x65F6;&#x5019;&#x4F1A;&#x662F;&#x4E00;&#x4E2A;&#x6709;&#x610F;&#x4E49;&#x7684;&#x56FE;</span>
                                  )

conv3_1 = tf.layers.conv2d(pooling2,
                         <span class="hljs-number">32</span>, <span class="hljs-comment"># output channel number</span>
                         (<span class="hljs-number">3</span>,<span class="hljs-number">3</span>), <span class="hljs-comment"># kernal size</span>
                         padding = <span class="hljs-string">&apos;same&apos;</span>, <span class="hljs-comment"># same &#x4EE3;&#x8868;&#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5927;&#x5C0F;&#x6CA1;&#x6709;&#x53D8;&#x5316;&#xFF0C;valid &#x4EE3;&#x8868;&#x4E0D;&#x505A;padding</span>
                         activation = tf.nn.relu,
                         name = <span class="hljs-string">&apos;conv3_1&apos;</span>
                         )

conv3_2 = tf.layers.conv2d(conv3_1,
                         <span class="hljs-number">32</span>, <span class="hljs-comment"># output channel number</span>
                         (<span class="hljs-number">3</span>,<span class="hljs-number">3</span>), <span class="hljs-comment"># kernal size</span>
                         padding = <span class="hljs-string">&apos;same&apos;</span>, <span class="hljs-comment"># same &#x4EE3;&#x8868;&#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5927;&#x5C0F;&#x6CA1;&#x6709;&#x53D8;&#x5316;&#xFF0C;valid &#x4EE3;&#x8868;&#x4E0D;&#x505A;padding</span>
                         activation = tf.nn.relu,
                         name = <span class="hljs-string">&apos;conv3_2&apos;</span>
                         )
<span class="hljs-comment"># 4*4*32</span>
pooling3 = tf.layers.max_pooling2d(conv3_2,
                                   (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), <span class="hljs-comment"># kernal size</span>
                                   (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), <span class="hljs-comment"># stride</span>
                                   name = <span class="hljs-string">&apos;pool3&apos;</span> <span class="hljs-comment"># name&#x4E3A;&#x4E86;&#x7ED9;&#x8FD9;&#x4E00;&#x5C42;&#x505A;&#x4E00;&#x4E2A;&#x547D;&#x540D;&#xFF0C;&#x8FD9;&#x6837;&#x4F1A;&#x8BA9;&#x56FE;&#x6253;&#x5370;&#x51FA;&#x6765;&#x7684;&#x65F6;&#x5019;&#x4F1A;&#x662F;&#x4E00;&#x4E2A;&#x6709;&#x610F;&#x4E49;&#x7684;&#x56FE;</span>
                                  )
</code></pre>
<p>&#x8BAD;&#x7EC3;10000&#x6B21; &#x53EF;&#x4EE5;&#x8FBE;&#x5230;&#x767E;&#x5206;&#x4E4B;70&#x7684;&#x51C6;&#x786E;&#x7387;</p>
<pre><code>
[Train] Step: 500, loss: 1.92473, acc: 0.45000
[Train] Step: 1000, loss: 1.49288, acc: 0.35000
[Train] Step: 1500, loss: 1.30839, acc: 0.55000
[Train] Step: 2000, loss: 1.41633, acc: 0.40000
[Train] Step: 2500, loss: 1.10951, acc: 0.60000
[Train] Step: 3000, loss: 1.15743, acc: 0.65000
[Train] Step: 3500, loss: 0.93834, acc: 0.70000
[Train] Step: 4000, loss: 0.76699, acc: 0.80000
[Train] Step: 4500, loss: 0.71109, acc: 0.70000
[Train] Step: 5000, loss: 0.75763, acc: 0.75000
(10000, 3072)
(10000,)
[Test ] Step: 5000, acc: 0.67500
[Train] Step: 5500, loss: 0.98661, acc: 0.65000
[Train] Step: 6000, loss: 1.43098, acc: 0.50000
[Train] Step: 6500, loss: 0.86575, acc: 0.70000
[Train] Step: 7000, loss: 0.80474, acc: 0.65000
[Train] Step: 7500, loss: 0.60132, acc: 0.85000
[Train] Step: 8000, loss: 0.66683, acc: 0.80000
[Train] Step: 8500, loss: 0.56874, acc: 0.85000
[Train] Step: 9000, loss: 0.68185, acc: 0.70000
[Train] Step: 9500, loss: 0.83302, acc: 0.70000
[Train] Step: 10000, loss: 0.87228, acc: 0.70000
(10000, 3072)
(10000,)
[Test ] Step: 10000, acc: 0.72700
</code></pre></li>
<li><h3 id="resnet&#x5B9E;&#x6218;">RESNET&#x5B9E;&#x6218;</h3>
<p>&#x5148;&#x6765;&#x56DE;&#x987E;&#x4E00;&#x4E0B;RESNET&#x7684;&#x7F51;&#x7EDC;&#x7ED3;&#x6784;</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7220971-a971b72e15fefbe1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>RESNET&#x662F;&#x5148;&#x7ECF;&#x8FC7;&#x4E86;&#x4E00;&#x4E2A;&#x5377;&#x79EF;&#x5C42;&#xFF0C;&#x53C8;&#x7ECF;&#x8FC7;&#x4E86;&#x4E00;&#x4E2A;&#x6C60;&#x5316;&#x5C42;&#xFF0C;&#x7136;&#x540E;&#x518D;&#x7ECF;&#x8FC7;&#x82E5;&#x5E72;&#x4E2A;&#x6B8B;&#x5DEE;&#x8FDE;&#x63A5;&#x5757;</p>
<p>&#x8FD9;&#x91CC;&#x6BCF;&#x7ECF;&#x8FC7;&#x4E00;&#x4E2A;&#x6B8B;&#x5DEE;&#x8FDE;&#x63A5;&#x5757;&#x4EE5;&#x540E;&#xFF0C;&#x53EF;&#x80FD;&#x4F1A;&#x7ECF;&#x8FC7;&#x4E00;&#x4E2A;&#x964D;&#x91C7;&#x6837;&#x7684;&#x8FC7;&#x7A0B;</p>
<p>&#x6240;&#x8C13;&#x964D;&#x91C7;&#x6837;&#x5C31;&#x662F;&#x4E4B;&#x524D;&#x7684;maxpooling&#x6216;&#x8005;&#x5377;&#x79EF;&#x5C42;&#x7684;&#x6B65;&#x957F;&#x7B49;&#x4E8E;2</p>
<p>&#x5728;&#x4E0A;&#x9762;&#x7684;ResNet&#x4E2D;&#xFF0C;&#x7ECF;&#x8FC7;&#x4E86;&#x56DB;&#x6B21;&#x964D;&#x91C7;&#x6837;&#x7684;&#x8FC7;&#x7A0B;&#xFF0C;&#x4F46;&#x662F;&#x7531;&#x4E8E;&#x6211;&#x4EEC;&#x7684;&#x5B9E;&#x6218;&#x4F7F;&#x7528;&#x7684;&#x56FE;&#x7247;&#x662F;32*32&#x7684;&#x672C;&#x8EAB;&#x5C31;&#x6BD4;&#x8F83;&#x5C0F;&#xFF0C;&#x6240;&#x4EE5;&#x4E0D;&#x4F1A;&#x7ECF;&#x8FC7;&#x592A;&#x591A;&#x7684;&#x964D;&#x91C7;&#x6837;&#xFF0C;&#x4E5F;&#x4E0D;&#x4F1A;&#x9996;&#x5148;&#x7ECF;&#x8FC7;maxpooling&#x5C42;</p>
<p>&#x5728;&#x964D;&#x91C7;&#x6837;&#x7684;&#x8FC7;&#x7A0B;&#x4E2D;&#x53EF;&#x80FD;&#x4F1A;&#x51FA;&#x73B0;&#x7684;&#x4E00;&#x4E2A;&#x95EE;&#x9898;&#x662F;&#xFF1A;&#x6B8B;&#x5DEE;&#x6709;&#x4E24;&#x90E8;&#x5206;&#x7EC4;&#x6210;&#xFF0C;&#x4E00;&#x90E8;&#x5206;&#x662F;&#x5377;&#x79EF;&#x64CD;&#x4F5C;&#xFF0C;&#x4E00;&#x90E8;&#x5206;&#x662F;&#x6052;&#x7B49;&#x53D8;&#x6362;&#xFF0C;&#x5982;&#x679C;&#x5377;&#x53CA;&#x64CD;&#x4F5C;&#x964D;&#x91C7;&#x6837;&#x4E86;&#xFF0C;&#x90A3;&#x4E48;&#x4F1A;&#x5BFC;&#x81F4;&#x4E24;&#x90E8;&#x5206;&#x7684;&#x7EF4;&#x5EA6;&#x4E0D;&#x4E00;&#x6837;&#xFF0C;&#x8FD9;&#x65F6;&#x5019;&#x7684;&#x77E9;&#x9635;&#x52A0;&#x6CD5;&#x4F1A;&#x51FA;&#x95EE;&#x9898;&#x3002;&#x6240;&#x4EE5;&#x8FD9;&#x4E2A;&#x65F6;&#x5019;&#x9700;&#x8981;&#x989D;&#x5916;&#x8FDB;&#x884C;&#x4E00;&#x4E2A;&#x64CD;&#x4F5C;&#xFF0C;&#x5C31;&#x662F;&#x5982;&#x679C;&#x5377;&#x79EF;&#x505A;&#x4E86;&#x964D;&#x91C7;&#x6837;&#xFF0C;&#x90A3;&#x4E48;&#x6052;&#x7B49;&#x53D8;&#x5316;&#x4E5F;&#x8981;&#x505A;&#x4E00;&#x6B21;&#x964D;&#x91C7;&#x6837;&#xFF0C;&#x8FD9;&#x4E2A;&#x64CD;&#x4F5C;&#x4F7F;&#x7528;maxpooling&#x6765;&#x505A;&#x3002;</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7220971-61a447ee1fa2981a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
</li>
</ul>
<p>  &#x5148;&#x5B9A;&#x4E49;&#x6B8B;&#x5DEE;&#x5757;&#x7684;&#x5B9E;&#x73B0;&#x65B9;&#x6CD5;</p>
<pre><code>  &quot;&quot;&quot;
  x&#x662F;&#x8F93;&#x5165;&#x6570;&#x636E;&#xFF0C;output_channel &#x662F;&#x8F93;&#x51FA;&#x901A;&#x9053;&#x6570;
  &#x4E3A;&#x4E86;&#x907F;&#x514D;&#x964D;&#x91C7;&#x6837;&#x5E26;&#x6765;&#x7684;&#x6570;&#x636E;&#x635F;&#x5931;&#xFF0C;&#x6211;&#x4EEC;&#x4F1A;&#x5728;&#x964D;&#x91C7;&#x6837;&#x7684;&#x65F6;&#x5019;&#x8BB2;output_channel&#x7FFB;&#x500D;
  &#x6240;&#x4EE5;&#x8FD9;&#x91CC;&#x5982;&#x679C;output_channel&#x662F;input_channel&#x7684;&#x4E8C;&#x500D;&#xFF0C;&#x5219;&#x8BF4;&#x660E;&#x9700;&#x8981;&#x964D;&#x91C7;&#x6837;
  &quot;&quot;&quot;

  def residual_block(x, output_channel):
      &quot;&quot;&quot;residual connection implementation&quot;&quot;&quot;
      input_channel = x.get_shape().as_list()[-1]
      if input_channel * 2 == output_channel:
          increase_dim = True
          strides = (2, 2)
      elif input_channel == output_channel:
          increase_dim = False
          strides = (1, 1)
      else:
           raise Exception(&quot;input channel can&apos;t match output channel&quot;)

      conv1 = tf.layers.conv2d(x,
                               output_channel,
                               (3,3),
                               strides = strides,
                               padding = &apos;same&apos;,
                               activation = tf.nn.relu,
                               name = &apos;conv1&apos;)
      conv2 = tf.layers.conv2d(conv1,
                               output_channel,
                               (3,3),
                               strides = (1,1),
                               padding = &apos;same&apos;,
                               activation = tf.nn.relu,
                               name = &apos;conv2&apos;)
      # &#x5904;&#x7406;&#x53E6;&#x4E00;&#x4E2A;&#x5206;&#x652F;&#xFF08;&#x6052;&#x7B49;&#x53D8;&#x6362;&#xFF09;
      if increase_dim:
          # &#x9700;&#x8981;&#x964D;&#x91C7;&#x6837;
          # [None,image_width,image_height,channel] -&gt; [,,,channel*2]
          pooled_x = tf.layers.average_pooling2d(x,
                                                (2,2), # pooling &#x6838;
                                                (2,2), # strides strides = pooling &#x4E0D;&#x91CD;&#x53E0;
                                                padding = &apos;valid&apos; # &#x8FD9;&#x91CC;&#x56FE;&#x50CF;&#x5927;&#x5C0F;&#x662F;32*32&#xFF0C;&#x90FD;&#x80FD;&#x9664;&#x5C3D;&#xFF0C;padding&#x662F;&#x4EC0;&#x4E48;&#x6CA1;&#x6709;&#x5173;&#x7CFB;
                                                )

          # average_pooling2d&#x4F7F;&#x5F97;&#x56FE;&#x7684;&#x5927;&#x5C0F;&#x53D8;&#x5316;&#x4E86;&#xFF0C;&#x4F46;&#x662F;output_channel&#x8FD8;&#x662F;&#x4E0D;&#x5339;&#x914D;&#xFF0C;&#x4E0B;&#x9762;&#x4FEE;&#x6539;output_channel
          padded_x = tf.pad(pooled_x,
                           [[0,0],
                            [0,0],
                            [0,0],
                            [input_channel // 2,input_channel //2]])
      else:
          padded_x = x
      output_x = conv2 + padded_x
      return output_x
</code></pre><p>  &#x7136;&#x540E;&#x5B9A;&#x4E49;&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;</p>
<p>  &#x5148;&#x4F7F;&#x7528;&#x4E00;&#x4E2A;&#x5377;&#x79EF;&#x5C42;&#xFF0C;&#x7136;&#x540E;&#x5FAA;&#x73AF;&#x521B;&#x5EFA;&#x6B8B;&#x5DEE;&#x5757;&#xFF0C;&#x6700;&#x540E;&#x8DDF;&#x4E00;&#x4E2A;&#x5168;&#x5C40;&#x7684;&#x6C60;&#x5316;&#xFF0C;&#x7136;&#x540E;&#x662F;&#x5168;&#x8FDE;&#x63A5;&#x5230;&#x8F93;&#x51FA;</p>
<p>  &#x5168;&#x5C40;&#x7684;&#x6C60;&#x5316;&#x548C;&#x666E;&#x901A;&#x7684;&#x6C60;&#x5316;&#x4E00;&#x6837;&#xFF0C;&#x53EA;&#x4E0D;&#x8FC7;&#x4ED6;&#x7684;size&#x548C;&#x56FE;&#x50CF;&#x7684;width&#xFF0C;height&#x4E00;&#x6837;&#x5927;&#xFF0C;&#x8FD9;&#x6837;&#x4E00;&#x4E2A;&#x56FE;&#x50CF;&#x7684;&#x8F93;&#x51FA;&#x5C31;&#x662F;&#x4E00;&#x4E2A;&#x6570;</p>
<pre><code>  def res_net(x,
              num_residual_blocks,  
              num_filter_base, 
              class_num): 
      &quot;&quot;&quot;residual network implementation&quot;&quot;&quot;
      &quot;&quot;&quot;
      Args:
      - x: &#x8F93;&#x5165;&#x6570;&#x636E;
      - num_residual_blocks: &#x6B8B;&#x5DEE;&#x94FE;&#x63A5;&#x5757;&#x6570; eg: [3,4,6,3]
      - num_filter_base: &#x6700;&#x521D;&#x7684;&#x901A;&#x9053;&#x6570;&#x76EE;
      - class_num: &#x7C7B;&#x522B;&#x6570;&#x76EE;
      &quot;&quot;&quot;
      # &#x9700;&#x8981;&#x505A;&#x591A;&#x5C11;&#x6B21;&#x964D;&#x91C7;&#x6837;
      num_subsampling = len(num_residual_blocks)
      layers = []
      # [None,image_width,image_height,channel] -&gt; [image_width,image_height,channel]
      # kernal size&#xFF1A;image_width,image_height
      input_size = x.get_shape().as_list()[1:]
      with tf.variable_scope(&apos;conv0&apos;):
          conv0 = tf.layers.conv2d(x,
                                   num_filter_base,
                                   (3,3),
                                   strides = (1,1),
                                   activation = tf.nn.relu,
                                   padding = &apos;same&apos;,
                                   name = &apos;conv0&apos;)
          layers.append(conv0)

      # eg: num_subsampling = 4 &#xFF0C;sample_id = [1&#xFF0C;2&#xFF0C;3&#xFF0C;4]   
      for sample_id in range(num_subsampling):
          for i in range(num_residual_blocks[sample_id]):
              with tf.variable_scope(&quot;conv%d_%d&quot; % (sample_id, i)):
                  conv = residual_block(
                      layers[-1],
                      num_filter_base * (2 ** sample_id)) # &#x6BCF;&#x6B21;&#x7FFB;&#x500D;
                  layers.append(conv)
      multiplier = 2 ** (num_subsampling - 1)
      assert layers[-1].get_shape().as_list()[1:] \
          == [input_size[0] / multiplier,
              input_size[1] / multiplier,
              num_filter_base * multiplier]
      with tf.variable_scope(&apos;fc&apos;):
          # layers[-1].shape : [None, width, height, channel]
          global_pool = tf.reduce_mean(layers[-1], [1, 2]) # pooling
          logits = tf.layers.dense(global_pool, class_num) # &#x5168;&#x8FDE;&#x63A5;
          layers.append(logits)
      return layers[-1]
</code></pre><p>  &#x7136;&#x540E;&#x4F7F;&#x7528;&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;</p>
<pre><code>  x = tf.placeholder(tf.float32, [None, 3072])
  y = tf.placeholder(tf.int64, [None])

  # &#x5C06;&#x5411;&#x91CF;&#x53D8;&#x6210;&#x5177;&#x6709;&#x4E09;&#x901A;&#x9053;&#x7684;&#x56FE;&#x7247;&#x7684;&#x683C;&#x5F0F;
  x_image = tf.reshape(x, [-1,3,32,32])
  # 32*32
  x_image = tf.transpose(x_image, perm = [0, 2, 3, 1])

  y_ = res_net(x_image, [2,3,2], 32, 10)


  # &#x4EA4;&#x53C9;&#x71B5;
  loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)
  # y_-&gt; softmax
  # y -&gt; one_hot
  # loss = ylogy_

  # bool
  predict = tf.argmax(y_, 1)
  # [1,0,1,1,1,0,0,0]
  correct_prediction = tf.equal(predict, y)
  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))

  with tf.name_scope(&apos;train_op&apos;):
      train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)
</code></pre><p>  &#x8FD9;&#x91CC;&#x8BAD;&#x7EC3;&#x7684;&#x7ED3;&#x6784;&#x8FC7;7000&#x6B21;&#x767E;&#x5206;&#x4E4B;67.&#x4E4B;&#x6240;&#x4EE5;&#x6BD4;VGG&#x4F4E;&#xFF0C;&#x662F;&#x56E0;&#x4E3A;&#x5F88;&#x591A;&#x4F18;&#x5316;&#x6CA1;&#x6709;&#x7528;&#x3002;&#x4F18;&#x5316;&#x540E;&#x7684;&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x5728;cifar10&#x4E0A;&#x53EF;&#x4EE5;&#x8FBE;&#x5230;94%&#x7684;&#x51C6;&#x786E;&#x7387;</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="4.2.3 卷积神经网络进阶inception-mobile-net.html" class="navigation navigation-prev " aria-label="Previous page: 4.2.3 卷积神经网络进阶(inception-mobile-net)">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="4.2.5 Inception-mobile_net实战.html" class="navigation navigation-next " aria-label="Next page: 4.2.5 Inception-mobile_net实战">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"4.2.4  VGG-ResNet实战","level":"1.5.2.4","depth":3,"next":{"title":"4.2.5 Inception-mobile_net实战","level":"1.5.2.5","depth":3,"path":"4.卷积神经网络/4.2 卷积神经网络进阶/4.2.5 Inception-mobile_net实战.md","ref":"4.卷积神经网络/4.2 卷积神经网络进阶/4.2.5 Inception-mobile_net实战.md","articles":[]},"previous":{"title":"4.2.3 卷积神经网络进阶(inception-mobile-net)","level":"1.5.2.3","depth":3,"path":"4.卷积神经网络/4.2 卷积神经网络进阶/4.2.3 卷积神经网络进阶inception-mobile-net.md","ref":"4.卷积神经网络/4.2 卷积神经网络进阶/4.2.3 卷积神经网络进阶inception-mobile-net.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["livereload"],"pluginsConfig":{"livereload":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"4.卷积神经网络/4.2 卷积神经网络进阶/4.2.4  VGG-ResNet实战.md","mtime":"2018-10-06T11:30:11.486Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2018-10-06T07:50:59.902Z"},"basePath":"../..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../../gitbook/gitbook.js"></script>
    <script src="../../gitbook/theme.js"></script>
    
        
        <script src="../../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

