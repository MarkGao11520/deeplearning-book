# 1.3 梯度下降与Transorflow基础

关于梯度下降的解可以参考这篇文章：https://www.jianshu.com/p/bf50fc0aa9f3 

Transorflow基础

- Google Brain的第二代机器学习框架

- 开源社区活跃

- 可扩展性强

- API建全，对用户友好

- 计算图模型

  - 命令式编程

    ![image.png](https://upload-images.jianshu.io/upload_images/7220971-88cdf7ca54c2c7c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

  - 声明式编程

    ![image.png](https://upload-images.jianshu.io/upload_images/7220971-9ab607eca3fa7b96.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

  - 命令式编程和声明式编程对比

    ![image.png](https://upload-images.jianshu.io/upload_images/7220971-4735130a905bca94.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

    ​    声明式编程的优点：得到计算图之后，很多计算图通用的特性就可以利用的上了，比如一个神经网络有多层，每一层的计算是相似的，所以曾与层直接的求导方式也是相似的，我们可以写一个通用的函数附加到神经网络上，这样的函数可以针对任意参数的神经网络去计算，这个时候如果有一个新的神经网络的话，我就不用去写一个新的函数去求导；

       而命令式编程却做不到，以为他的变量都是自己定义的

  - 神经网络的模型是实现设定好的，但是数据先前是不知道的，所以需要定义好神经网络之后，才能把数据输入进来，去调整参数，使得神经网络可以去符合这个数据，所以这就是Transorflow框架使用计算图模型的基础



