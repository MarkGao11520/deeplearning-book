# 4.2.3 卷积神经网络进阶(inception-mobile-net)

- ### Inception-Net

  - 工程优化 — 同样的参数数量更加有效率

    ![image.png](https://upload-images.jianshu.io/upload_images/7220971-4f8dea908fb9dd5f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

  - 深层网络遇到的问题

    - 更深的网络更容易过拟合
    - 更深的网络有更大的计算量
      - 稀疏网络虽然减少了参数但没有减少计算量

  - V1结构

    - 分组卷积

      相对于一个普通3\*3的卷积核，在inception-net中采用了多种卷积核，每种卷积核都可以进行扩展（多加一些层）形成一个组，组和组之间计算就不相互交叉了。不相互交叉就能降低计算量（相当于每个组的输入都不包含其他组的输入）

      ![image.png](https://upload-images.jianshu.io/upload_images/7220971-e58222cf6c523c5d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

    - Inception优势

      - 一层上同时使用多种卷积核,看到各种层级的feature
      - 不同组之间的feature不交叉计算,减少了计算量

    - 卷积计算量

      - 一个卷积层计算量

      ```
       ((kw*kh)*Ci)((oW*Oh)*Co)
       kw:卷积核的宽
       kh:卷积核的高
       ow:输出图像的宽
       oh:输出图像的高
       ci:输入的通道数
       co:输出的通道数
      ```

       ![image.png](https://upload-images.jianshu.io/upload_images/7220971-53b149a8937387bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

       ![image.png](https://upload-images.jianshu.io/upload_images/7220971-6c48cee197d3a0f3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

       ![image.png](https://upload-images.jianshu.io/upload_images/7220971-29edf068f658ecc6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

       我们可以继续优化Inception的参数数目和计算量，这里Inception比较高还是因为有一个5\*5的卷积核，那么我们可以用1\*1的卷积核去优化他，先使用1\*1做非线性变换，将输入通道数减小（比如从100通道变成25通道），然后再做5\*5的卷积，因为输入通道数变小了，所以参数数目和计算量肯定也就变小了

    - 用V1结构组装网络结构

      ![image-20181006121727260](/Users/gaowenfeng/Library/Application Support/typora-user-images/image-20181006121727260.png)

  - V2结构

    - 引入3\*3视野同等卷积替换

      ![image.png](https://upload-images.jianshu.io/upload_images/7220971-8bc24d4b0d6e86e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

  - v3结构
     ![image.png](https://upload-images.jianshu.io/upload_images/7220971-b0e544ad099ccf1b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

        - 3\*3不是最小卷积


            - 3\*3 = 1\*3 和 3\*1
            - 参数降低33%

  - v4结构


    - 引入skip connection
    
       就是残差链接（inceptionnet和resnet组合）
    
       ![image.png](https://upload-images.jianshu.io/upload_images/7220971-f7a2a6e4a70b493a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



- ### Mobile Net

  能够保证精度损失在可控制范围之内，可以大幅度降低参数数目和计算量

  - 模型结构

    - 引入深度可分离卷积

      下左图是普通的神经网络结构，下右图是深度可分离的神经网络结构，其中BN是归一化，后面会讲

      ![image.png](https://upload-images.jianshu.io/upload_images/7220971-38181b219ed82b1b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

    - 回顾InceptionNet

    - 分到极致

      首先使用1\*1 的卷积核将输入变成多通道，然后一个卷积核只关注其中的一个通道，关注某个通道后生成一个通道，在将所有输出通道拼接，降低了所有卷积核对输入的一个范畴

      ![image.png](https://upload-images.jianshu.io/upload_images/7220971-b967bac55c804715.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

  - 计算量对比

    ![image.png](https://upload-images.jianshu.io/upload_images/7220971-2545c9e26c8ef98a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

    优化比例：

    ```
    (Kw*Kh*Co*OW*Oh + Ci*Co*Ow*Oh) / (Kw*Kh*Ci*Co*OW*Oh) = 1/Ci+1/(Kw*Kh)
    ```

    深度可分离卷积可以大幅度降低参数数目和计算量，当然这么大幅度的降低肯定能够会带来精度的损失，但是经过试验表明，这个损失是可控的，可以控制在百分之10以内

- ### 不同模型结构优劣对比

  - 效果分析

    ![image.png](https://upload-images.jianshu.io/upload_images/7220971-5ad6ded3ba6bdf6f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

  - 效果层次分析

    ![image.png](https://upload-images.jianshu.io/upload_images/7220971-94a38d5f2258e979.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

  - 效果计算量分析

    ![image.png](https://upload-images.jianshu.io/upload_images/7220971-82c13262d09876df.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

    - 横坐标：计算量

    - 纵坐标：精准率

    - 圆圈大小：参数量多少

- 






